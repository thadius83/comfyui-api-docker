services:
  # Native ComfyUI with full UI (matches parent flux2-api primary service)
  comfyui:
    image: yanwk/comfyui-boot:cu128-slim
    container_name: comfyui-standalone
    restart: unless-stopped
    ports:
      - "8188:8188"
    volumes:
      - /srv/ai/models:/root/ComfyUI/models
      - ./output:/root/ComfyUI/output
      - ./custom_nodes:/root/ComfyUI/custom_nodes
      - /srv/ai/hf-cache:/root/.cache/huggingface/hub
      - ./user:/root/ComfyUI/user
    environment:
      - CLI_ARGS=--cuda-malloc --normalvram --disable-pinned-memory
      - HF_TOKEN=${HF_TOKEN}
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True,max_split_size_mb:128
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8188/queue"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
networks:
  default:
    driver: bridge
